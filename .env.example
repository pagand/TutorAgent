# AI Tutor App Environment Variables

# --- LLM Provider Settings ---
# Choose one: "ollama", "openai", "google", "bedrock"
LLM_PROVIDER="ollama"

# --- Ollama Settings (if LLM_PROVIDER="ollama") ---
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3" # Or use model specified in config.py default

# --- OpenAI Settings (if LLM_PROVIDER="openai") ---
# OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
# OPENAI_MODEL_NAME="gpt-4-turbo-preview" # Or use model specified in config.py default

# --- Google Gemini Settings (if LLM_PROVIDER="google") ---
# GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
# GOOGLE_MODEL_NAME="gemini-1.5-flash-latest" # Or use model specified in config.py default

# --- AWS Bedrock Settings (if LLM_PROVIDER="bedrock") ---
# AWS_ACCESS_KEY_ID="YOUR_AWS_ACCESS_KEY"
# AWS_SECRET_ACCESS_KEY="YOUR_AWS_SECRET_KEY"
# AWS_REGION_NAME="us-east-1" # Or your desired region
# BEDROCK_MODEL_ID="anthropic.claude-v2" # Example model ID