{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Tutor Debugging Session\n",
    "\n",
    "This notebook is designed for step-by-step debugging of the AI Tutor's core feedback loop. Each cell represents a single API call, allowing for careful inspection of the requests and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using User ID: debug_user_1761461888\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "USER_ID = f\"debug_user_{int(time.time())}\"\n",
    "QUESTION_NUMBER = 3 # A question we know the answer to\n",
    "INCORRECT_ANSWER = \"1\" # The 1-based index for 'δ (delta)'\n",
    "CORRECT_ANSWER = \"2\" # The 1-based index for 'ε (epsilon)'\n",
    "\n",
    "session = requests.Session()\n",
    "hint_data = {} # To store hint response\n",
    "\n",
    "print(f\"Using User ID: {USER_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"user_id\": \"debug_user_1761461888\",\n",
      "  \"created_at\": \"2025-10-26T06:58:13.203879\",\n",
      "  \"preferences\": {\n",
      "    \"hint_style_preference\": \"adaptive\",\n",
      "    \"intervention_preference\": \"manual\"\n",
      "  },\n",
      "  \"feedback_scores\": {},\n",
      "  \"skill_mastery\": [],\n",
      "  \"interaction_history\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\"user_id\": USER_ID}\n",
    "response = session.post(f\"{BASE_URL}/users/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"hint_style_preference\": \"adaptive\",\n",
      "  \"intervention_preference\": \"proactive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"intervention_preference\": \"proactive\",\n",
    "    \"hint_style_preference\": \"adaptive\"\n",
    "}\n",
    "response = session.put(f\"{BASE_URL}/users/{USER_ID}/preferences/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Submit an INCORRECT First Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"correct\": false,\n",
      "  \"correct_answer\": \"2\",\n",
      "  \"skill\": \"[LoRA-Quantization-Basics]\",\n",
      "  \"intervention_needed\": true,\n",
      "  \"current_mastery\": 0.17575757575757575\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"user_id\": USER_ID,\n",
    "    \"question_number\": QUESTION_NUMBER,\n",
    "    \"user_answer\": INCORRECT_ANSWER\n",
    "}\n",
    "response = session.post(f\"{BASE_URL}/answer/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Request a Hint\n",
    "\n",
    "This is the most critical step. We need to inspect the full response body to see if `context` and `final_prompt` are being populated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"question_number\": 3,\n",
      "  \"hint\": \"The document uses a Greek letter to represent the quantization error. Review the equations and surrounding text in section 2.2 to find the correct symbol.\",\n",
      "  \"user_id\": \"debug_user_1761461888\",\n",
      "  \"hint_style\": \"Conceptual\",\n",
      "  \"pre_hint_mastery\": 0.17575757575757575,\n",
      "  \"context\": \"Quantization-Aware Low-Rank Adaptation (QA-LoRA) \\u2014 \\nA Code + Concept Deep Dive \\n \\n1. Introduction & Motivation \\nParameter-efficient fine-tuning (PEFT) methods like LoRA allow us to adapt large language \\nmodels by inserting small low-rank adapters, freezing the base weights, and only training \\nadapter components. QLoRA extends this by quantizing the base model (e.g. to 4 bits) and \\nkeeping it frozen, while training LoRA adapters in higher precision (e.g. 16- or 32-bit) on top of \\nit. \\nOne challenge: quantizing the base model introduces quantization error (i.e. the quantized \\nweight (\\\\hat W) deviates from the original full-precision weight (W)). That error can degrade how \\nwell the adapter\\u2019s updates behave, because LoRA\\u2019s updates were originally conceived \\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects.\\n\\nIn QLoRA, instead of storing (W) in full precision, we quantize: \\n[\\u200b\\n \\\\hat W = Q(W)\\u200b\\n ] \\nThen the model uses (\\\\hat W) as its base, and adaptations are: \\n[\\u200b\\n \\\\hat W + A B\\u200b\\n ] \\nThe challenge: (Q(W)) introduces error (\\\\varepsilon = \\\\hat W - W). \\n2.2 Quantization Error and Its Effect \\nThe quantization error behaves like: \\n[\\u200b\\n \\\\hat W = W + \\\\varepsilon\\u200b\\n ] \\nso the effective new weight is: \\n[\\u200b\\n W_{\\\\text{eff}} = W + \\\\varepsilon + A B.\\u200b\\n ] \\nIf (\\\\varepsilon) is nontrivial, it can distort the gradient landscape that the LoRA adapter sees \\n(since residual errors shift activations), and in worst case the adapter \\u201clearns to cancel\\u201d \\nquantization noise rather than learn the true task adaptation. \\nQuAILoRA aims to preemptively counteract (\\\\varepsilon) by adjusting (A, B) initialization. \\n2.3 QuAILoRA\\u2019s Correction / Initialization Trick \\nThe core idea: during initialization of (A, B), compute an estimate of (\\\\varepsilon) (or at least its \\ndominant component) and initialize the adapter so that: \\n[\\u200b\\n\\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects. \\nIn short: QuAILoRA sits between QLoRA and LoRA and \\u201cadjusts for quantization error at \\ninitialization\\u201d to yield better adaptation under quantization constraints. \\n \\n2. Core Theory & Equations \\n2.1 Standard LoRA + Quantization Setup \\nIn LoRA, for a transformer linear weight (W \\\\in \\\\mathbb{R}^{d_{\\\\text{out}} \\\\times d_{\\\\text{in}}}), \\none inserts a low-rank decomposition: \\n[\\u200b\\n W_{\\\\text{new}} = W + \\\\Delta W, \\\\quad \\\\Delta W = A B\\u200b\\n ] \\nHere: \\n\\u25cf\\u200b (A \\\\in \\\\mathbb{R}^{d_{\\\\text{out}} \\\\times r})\\u200b\\n \\n\\u25cf\\u200b (B \\\\in \\\\mathbb{R}^{r \\\\times d_{\\\\text{in}}})\\u200b\\n \\n\\u25cf\\u200b Only (A, B) are trainable; (W) is frozen.\\u200b\",\n",
      "  \"final_prompt\": \"\\n**Instructions:** You are an AI Tutor. Your goal is to provide a helpful, conceptual hint to a student based on their question and their answer attempt, using the provided context. Focus on clarifying the core concept without giving away the direct answer. If the context isn't relevant, acknowledge that and offer general advice related to the question's topic. Keep the hint concise, encouraging, and focused.\\n\\n**Retrieved Context:**\\n---------------------\\nQuantization-Aware Low-Rank Adaptation (QA-LoRA) \\u2014 \\nA Code + Concept Deep Dive \\n \\n1. Introduction & Motivation \\nParameter-efficient fine-tuning (PEFT) methods like LoRA allow us to adapt large language \\nmodels by inserting small low-rank adapters, freezing the base weights, and only training \\nadapter components. QLoRA extends this by quantizing the base model (e.g. to 4 bits) and \\nkeeping it frozen, while training LoRA adapters in higher precision (e.g. 16- or 32-bit) on top of \\nit. \\nOne challenge: quantizing the base model introduces quantization error (i.e. the quantized \\nweight (\\\\hat W) deviates from the original full-precision weight (W)). That error can degrade how \\nwell the adapter\\u2019s updates behave, because LoRA\\u2019s updates were originally conceived \\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects.\\n\\nIn QLoRA, instead of storing (W) in full precision, we quantize: \\n[\\u200b\\n \\\\hat W = Q(W)\\u200b\\n ] \\nThen the model uses (\\\\hat W) as its base, and adaptations are: \\n[\\u200b\\n \\\\hat W + A B\\u200b\\n ] \\nThe challenge: (Q(W)) introduces error (\\\\varepsilon = \\\\hat W - W). \\n2.2 Quantization Error and Its Effect \\nThe quantization error behaves like: \\n[\\u200b\\n \\\\hat W = W + \\\\varepsilon\\u200b\\n ] \\nso the effective new weight is: \\n[\\u200b\\n W_{\\\\text{eff}} = W + \\\\varepsilon + A B.\\u200b\\n ] \\nIf (\\\\varepsilon) is nontrivial, it can distort the gradient landscape that the LoRA adapter sees \\n(since residual errors shift activations), and in worst case the adapter \\u201clearns to cancel\\u201d \\nquantization noise rather than learn the true task adaptation. \\nQuAILoRA aims to preemptively counteract (\\\\varepsilon) by adjusting (A, B) initialization. \\n2.3 QuAILoRA\\u2019s Correction / Initialization Trick \\nThe core idea: during initialization of (A, B), compute an estimate of (\\\\varepsilon) (or at least its \\ndominant component) and initialize the adapter so that: \\n[\\u200b\\n\\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects. \\nIn short: QuAILoRA sits between QLoRA and LoRA and \\u201cadjusts for quantization error at \\ninitialization\\u201d to yield better adaptation under quantization constraints. \\n \\n2. Core Theory & Equations \\n2.1 Standard LoRA + Quantization Setup \\nIn LoRA, for a transformer linear weight (W \\\\in \\\\mathbb{R}^{d_{\\\\text{out}} \\\\times d_{\\\\text{in}}}), \\none inserts a low-rank decomposition: \\n[\\u200b\\n W_{\\\\text{new}} = W + \\\\Delta W, \\\\quad \\\\Delta W = A B\\u200b\\n ] \\nHere: \\n\\u25cf\\u200b (A \\\\in \\\\mathbb{R}^{d_{\\\\text{out}} \\\\times r})\\u200b\\n \\n\\u25cf\\u200b (B \\\\in \\\\mathbb{R}^{r \\\\times d_{\\\\text{in}}})\\u200b\\n \\n\\u25cf\\u200b Only (A, B) are trainable; (W) is frozen.\\u200b\\n---------------------\\n\\n**Student's Recent Interaction History (<q> shows the question and <a> shows students answer, and <h> shows the provided hints):**\\n---------------------\\n- <q>What symbol does the document use to denote the quantization error between the quantized weight and the original full-precision weight?</q>; <a>\\u03b4 (delta)</a> (Incorrect)\\n---------------------\\n\\n**Student's Question:** What symbol does the document use to denote the quantization error between the quantized weight and the original full-precision weight?\\n- \\u03b4 (delta)\\n- \\u03b5 (epsilon)\\n- \\u03b7 (eta)\\n- \\u03ba (kappa)\\n\\n**Student's Answer Attempt:** 1\\n\\n**Hint:**\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"user_id\": USER_ID,\n",
    "    \"question_number\": QUESTION_NUMBER,\n",
    "    \"user_answer\": INCORRECT_ANSWER\n",
    "}\n",
    "response = session.post(f\"{BASE_URL}/hints/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "if response.ok:\n",
    "    hint_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Submit a CORRECT Second Answer (with Hint Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"correct\": true,\n",
      "  \"correct_answer\": \"2\",\n",
      "  \"skill\": \"[LoRA-Quantization-Basics]\",\n",
      "  \"intervention_needed\": false,\n",
      "  \"current_mastery\": 0.5662288930581614\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if not hint_data:\n",
    "    print(\"Cannot proceed: hint_data was not populated in the previous step.\")\n",
    "else:\n",
    "    payload = {\n",
    "        \"user_id\": USER_ID,\n",
    "        \"question_number\": QUESTION_NUMBER,\n",
    "        \"user_answer\": CORRECT_ANSWER,\n",
    "        \"hint_shown\": True,\n",
    "        \"hint_style_used\": hint_data.get(\"hint_style\"),\n",
    "        \"hint_text\": hint_data.get(\"hint\"),\n",
    "        \"pre_hint_mastery\": hint_data.get(\"pre_hint_mastery\"),\n",
    "        \"feedback_rating\": 5 # Assume a good hint\n",
    "    }\n",
    "    response = session.post(f\"{BASE_URL}/answer/\", json=payload)\n",
    "\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(json.dumps(response.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
