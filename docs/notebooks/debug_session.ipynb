{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Tutor Debugging Session\n",
    "\n",
    "This notebook is designed for step-by-step debugging of the AI Tutor's core feedback loop. Each cell represents a single API call, allowing for careful inspection of the requests and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using User ID: debug_user_1767656021\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "USER_ID = f\"debug_user_{int(time.time())}\"\n",
    "QUESTION_NUMBER = 3 # A question we know the answer to\n",
    "INCORRECT_ANSWER = \"1\" # The 1-based index for 'δ (delta)'\n",
    "CORRECT_ANSWER = \"2\" # The 1-based index for 'ε (epsilon)'\n",
    "\n",
    "session = requests.Session()\n",
    "hint_data = {} # To store hint response\n",
    "\n",
    "print(f\"Using User ID: {USER_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"user_id\": \"debug_user_1767656021\",\n",
      "  \"created_at\": \"2026-01-05T23:33:44.474543\",\n",
      "  \"preferences\": {\n",
      "    \"hint_style_preference\": \"adaptive\",\n",
      "    \"intervention_preference\": \"manual\"\n",
      "  },\n",
      "  \"feedback_scores\": {},\n",
      "  \"skill_mastery\": [],\n",
      "  \"interaction_history\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\"user_id\": USER_ID}\n",
    "response = session.post(f\"{BASE_URL}/users/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"hint_style_preference\": \"adaptive\",\n",
      "  \"intervention_preference\": \"proactive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"intervention_preference\": \"proactive\",\n",
    "    \"hint_style_preference\": \"adaptive\" #\"Socratic Question\"\n",
    "}\n",
    "response = session.put(f\"{BASE_URL}/users/{USER_ID}/preferences/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Submit an INCORRECT First Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"correct\": false,\n",
      "  \"correct_answer\": \"2\",\n",
      "  \"skill\": \"[LoRA-Quantization-Basics]\",\n",
      "  \"intervention_needed\": true,\n",
      "  \"current_mastery\": 0.17575757575757575\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"user_id\": USER_ID,\n",
    "    \"question_number\": QUESTION_NUMBER,\n",
    "    \"user_answer\": INCORRECT_ANSWER\n",
    "}\n",
    "response = session.post(f\"{BASE_URL}/answer/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.5: send a skipped answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"correct\": false,\n",
      "  \"correct_answer\": \"2\",\n",
      "  \"skill\": \"[LoRA-Quantization-Basics]\",\n",
      "  \"intervention_needed\": true,\n",
      "  \"current_mastery\": 0.17575757575757575\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "        \"user_id\": USER_ID,\n",
    "        \"question_number\": QUESTION_NUMBER,\n",
    "        \"skipped\": True\n",
    "    }\n",
    "response = session.post(f\"{BASE_URL}/answer/\", json=payload)\n",
    " \n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Request a Hint\n",
    "\n",
    "This is the most critical step. We need to inspect the full response body to see if `context` and `final_prompt` are being populated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"question_number\": 3,\n",
      "  \"hint\": \"Let's consider a similar problem to understand how quantization error can negatively impact LoRA adapter training.\\n\\n**Problem:** How does quantization error affect the LoRA adapter's ability to learn?\\n\\nHere's a step-by-step breakdown:\\n\\n1.  **The Ideal Scenario (No Quantization):** In a perfect world, without quantization, the LoRA adapter learns to adjust the full-precision base model's weights to improve performance on a specific task. The adapter receives\",\n",
      "  \"user_id\": \"debug_user_1767656021\",\n",
      "  \"hint_style\": \"Worked Example\",\n",
      "  \"pre_hint_mastery\": 0.17142857171212977,\n",
      "  \"context\": \"behavior is perturbed by quantization noise; the adapter must \\u201cwork around\\u201d that.\\u200b\\n \\n\\u25cf\\u200b QA-LoRA\\u2019s insight: make the LoRA adaptation aware of quantization during training, \\nnot just afterward. It blends quantization and adaptation more tightly. (Hugging Face)\\u200b\\n \\nIn practice, QA-LoRA provides two advantages:\\n\\nthen the initialization step might not hurt but offers minimal gain.\\u200b\\n \\nWhen to use \\u2014 heuristics: \\n\\u25cf\\u200b If your quantized model (e.g., 4-bit QLoRA) is underperforming relative to expectation.\\u200b\\n \\n\\u25cf\\u200b If you can afford a small calibration step and have full-precision vs quantized weight \\naccess.\\u200b\\n \\n\\u25cf\\u200b If your adapter rank is moderate-to-large (so initialization has expressive capacity).\\u200b\\n \\n\\u25cf\\u200b Less beneficial if quantization error is already minimal (e.g. NF4 + nice quant scheme).\\u200b\\n \\nWhy QA-LoRA? (Beyond QLoRA) \\nLet\\u2019s start with the problem QA-LoRA tries to solve: \\n\\u25cf\\u200b QLoRA uses a frozen quantized base model (e.g. 4-bit) and learns LoRA adapters on \\ntop, backpropagating through quantization. (arXiv)\\u200b\\n \\n\\u25cf\\u200b But quantization introduces errors / distortions. The base model\\u2019s activations / weight \\nbehavior is perturbed by quantization noise; the adapter must \\u201cwork around\\u201d that.\\u200b\\n \\n\\u25cf\\u200b QA-LoRA\\u2019s insight: make the LoRA adaptation aware of quantization during training,\\n\\nQuantization-Aware Low-Rank Adaptation (QA-LoRA) \\u2014 \\nA Code + Concept Deep Dive \\n \\n1. Introduction & Motivation \\nParameter-efficient fine-tuning (PEFT) methods like LoRA allow us to adapt large language \\nmodels by inserting small low-rank adapters, freezing the base weights, and only training \\nadapter components. QLoRA extends this by quantizing the base model (e.g. to 4 bits) and \\nkeeping it frozen, while training LoRA adapters in higher precision (e.g. 16- or 32-bit) on top of \\nit. \\nOne challenge: quantizing the base model introduces quantization error (i.e. the quantized \\nweight (\\\\hat W) deviates from the original full-precision weight (W)). That error can degrade how \\nwell the adapter\\u2019s updates behave, because LoRA\\u2019s updates were originally conceived \\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects.\",\n",
      "  \"final_prompt\": \"\\n**Instructions:** You are an AI Tutor. Your goal is to provide a hint by showing a step-by-step solution to a similar, but distinct, problem. Use the provided context to create a relevant example. Clearly label the steps. Do not solve the student's exact question.\\n\\n**Retrieved Context:**\\n---------------------\\nbehavior is perturbed by quantization noise; the adapter must \\u201cwork around\\u201d that.\\u200b\\n \\n\\u25cf\\u200b QA-LoRA\\u2019s insight: make the LoRA adaptation aware of quantization during training, \\nnot just afterward. It blends quantization and adaptation more tightly. (Hugging Face)\\u200b\\n \\nIn practice, QA-LoRA provides two advantages:\\n\\nthen the initialization step might not hurt but offers minimal gain.\\u200b\\n \\nWhen to use \\u2014 heuristics: \\n\\u25cf\\u200b If your quantized model (e.g., 4-bit QLoRA) is underperforming relative to expectation.\\u200b\\n \\n\\u25cf\\u200b If you can afford a small calibration step and have full-precision vs quantized weight \\naccess.\\u200b\\n \\n\\u25cf\\u200b If your adapter rank is moderate-to-large (so initialization has expressive capacity).\\u200b\\n \\n\\u25cf\\u200b Less beneficial if quantization error is already minimal (e.g. NF4 + nice quant scheme).\\u200b\\n \\nWhy QA-LoRA? (Beyond QLoRA) \\nLet\\u2019s start with the problem QA-LoRA tries to solve: \\n\\u25cf\\u200b QLoRA uses a frozen quantized base model (e.g. 4-bit) and learns LoRA adapters on \\ntop, backpropagating through quantization. (arXiv)\\u200b\\n \\n\\u25cf\\u200b But quantization introduces errors / distortions. The base model\\u2019s activations / weight \\nbehavior is perturbed by quantization noise; the adapter must \\u201cwork around\\u201d that.\\u200b\\n \\n\\u25cf\\u200b QA-LoRA\\u2019s insight: make the LoRA adaptation aware of quantization during training,\\n\\nQuantization-Aware Low-Rank Adaptation (QA-LoRA) \\u2014 \\nA Code + Concept Deep Dive \\n \\n1. Introduction & Motivation \\nParameter-efficient fine-tuning (PEFT) methods like LoRA allow us to adapt large language \\nmodels by inserting small low-rank adapters, freezing the base weights, and only training \\nadapter components. QLoRA extends this by quantizing the base model (e.g. to 4 bits) and \\nkeeping it frozen, while training LoRA adapters in higher precision (e.g. 16- or 32-bit) on top of \\nit. \\nOne challenge: quantizing the base model introduces quantization error (i.e. the quantized \\nweight (\\\\hat W) deviates from the original full-precision weight (W)). That error can degrade how \\nwell the adapter\\u2019s updates behave, because LoRA\\u2019s updates were originally conceived \\nassuming access to an accurate base weight. QuAILoRA is a technique that initializes the \\nLoRA adapter weights in a way that is aware of the quantization error, reducing the negative \\neffects.\\n---------------------\\n\\n**Student's Recent Interaction History (<q> shows the question and <a> shows students answer, and <h> shows the provided hints):**\\n---------------------\\n- <q>How can significant quantization error \\u03b5 negatively affect LoRA adapter training?</q>; <h>Hint Style Used: Worked Example: Let's consider a similar problem to understand how quantization error can negatively impact LoRA adapter training.  **Problem:** How does quantization error affect the LoRA adapter's ability to learn?  **Here's a step-by-step breakdown:**  1.  **The Ideal Scenario (No Quantization):** In a perfect world, without quantization, the LoRA adapter learns to adjust the full-precision base model's weights to improve performance on a specific task. The adapter</h>; <a>It speeds up convergence incorrectly</a> (Incorrect)\\n- <q>How can significant quantization error \\u03b5 negatively affect LoRA adapter training?</q>; <h>Hint Style Used: Analogy: Imagine you're trying to build a house, but the blueprints you're using are slightly blurry and inaccurate due to a printing error (quantization error). You're still trying to build the house (train the adapter), but because the blueprints are wrong, you might end up building something that doesn't quite match the original design, or even worse, you might focus on correcting the blueprint errors instead of building the house correctly.</h>; <a>It speeds up convergence incorrectly</a> (Incorrect)\\n- <q>How can significant quantization error \\u03b5 negatively affect LoRA adapter training?</q>; <h>Hint Style Used: Analogy: Imagine you're trying to build a house, but the blueprints you're using are slightly blurry and inaccurate due to a printing error (quantization error). You're still trying to build the house (train the adapter), but because the blueprints are wrong, you might end up building something that doesn't quite match the original design, or even worse, you might focus on correcting the blueprint errors instead of building the house correctly.</h>; <a>It speeds up convergence incorrectly</a> (Incorrect)\\n- <q>How can significant quantization error \\u03b5 negatively affect LoRA adapter training?</q>; <h>Hint Style Used: Analogy: Imagine you're trying to build a house, but the blueprints you're using are slightly blurry and inaccurate due to a printing error (quantization error). You're still trying to build the house (train the adapter), but because the blueprints are wrong, you might end up building something that doesn't quite match the original design, or even worse, you might focus on correcting the blueprint errors instead of building the house correctly.</h>; <a>It speeds up convergence incorrectly</a> (Incorrect)\\n- <q>How can significant quantization error \\u03b5 negatively affect LoRA adapter training?</q>; <h>Hint Style Used: Analogy: Imagine you're trying to build a house, but the blueprints you're using are slightly blurry and inaccurate due to a printing error (quantization error). You're still trying to build the house (train the adapter), but because the blueprints are wrong, you might end up building something that doesn't quite match the original design, or even worse, you might focus on correcting the blueprint errors instead of building the house correctly.</h>; <a>It speeds up convergence incorrectly</a> (Incorrect)\\n---------------------\\n\\n**Student's Question:** How can significant quantization error \\u03b5 negatively affect LoRA adapter training?\\n- It speeds up convergence incorrectly\\n- It makes the adapter learn to cancel quantization noise instead of the true task adaptation\\n- It allows training of the full base weights\\n- It makes the model immune to overfitting\\n\\n**Student's Answer Attempt:** 1\\n\\n**Hint (as a worked example for a similar problem):**\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"user_id\": USER_ID,\n",
    "    \"question_number\": QUESTION_NUMBER,\n",
    "    \"user_answer\": INCORRECT_ANSWER\n",
    "}\n",
    "response = session.post(f\"{BASE_URL}/hints/\", json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "if response.ok:\n",
    "    hint_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Submit a CORRECT Second Answer (with Hint Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"correct\": false,\n",
      "  \"correct_answer\": \"2\",\n",
      "  \"skill\": \"[LoRA-Quantization-Basics]\",\n",
      "  \"intervention_needed\": true,\n",
      "  \"current_mastery\": 0.17142857171212977\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if not hint_data:\n",
    "    print(\"Cannot proceed: hint_data was not populated in the previous step.\")\n",
    "else:\n",
    "    payload = {\n",
    "        \"user_id\": USER_ID,\n",
    "        \"question_number\": QUESTION_NUMBER,\n",
    "        \"user_answer\": CORRECT_ANSWER,\n",
    "        \"hint_shown\": True,\n",
    "        \"hint_style_used\": hint_data.get(\"hint_style\"),\n",
    "        \"hint_text\": hint_data.get(\"hint\"),\n",
    "        \"pre_hint_mastery\": hint_data.get(\"pre_hint_mastery\"),\n",
    "        \"feedback_rating\": 4 # Assume a good hint\n",
    "    }\n",
    "    response = session.post(f\"{BASE_URL}/answer/\", json=payload)\n",
    "\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(json.dumps(response.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
